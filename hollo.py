import streamlit as st
import requests
from bs4 import BeautifulSoup
import re
import json
import openai

# Configuration de l'interface
st.set_page_config(page_title="Web Scraper", layout="wide")

# Titre de l'application avec une meilleure mise en forme
st.title("üîç Web Scraper avec IA et Streamlit")
st.markdown("### Extraire et analyser intelligemment des informations depuis une page web")

# Mise en place des colonnes pour afficher les menus
col1, col2, col3 = st.columns([3, 1, 1])

with col1:
    # Entr√©e pour l'URL
    url = st.text_input("üåç Entrez l'URL du site web √† scraper :", placeholder="https://exemple.com")

with col2:
    # Menu d√©roulant pour choisir une fonctionnalit√© standard
    option = st.selectbox(
        "üìå Choisissez une fonctionnalit√© :",
        ["Afficher le titre", "Afficher tout le texte", "Afficher toutes les balises H1",
         "Afficher tous les paragraphes",
         "Afficher tous les liens", "Afficher toutes les images", "Afficher le nombre total de mots",
         "Afficher les m√©tadonn√©es",
         "Extraire les num√©ros de t√©l√©phone", "Extraire les adresses e-mail",
         "Premium - Analyser la structure HTML", "Premium - Extraire les hashtags", "Premium - Analyser le SEO",
         "Premium - D√©tecter les r√©seaux sociaux", "Premium - Exporter en JSON"]
    )

with col3:
    # Menu d√©roulant pour choisir une fonctionnalit√© IA
    option_ai = st.selectbox(
        "ü§ñ Fonctionnalit√©s IA :",
        ["Aucune", "R√©sum√© automatique", "Analyse de sentiment", "Classification du contenu",
         "D√©tection des entit√©s nomm√©es", "G√©n√©ration de mots-cl√©s"]
    )
    start_button = st.button("Lancer l'analyse")

if start_button and url:
    try:
        # Requ√™te HTTP pour obtenir le contenu de la page
        response = requests.get(url)
        response.raise_for_status()

        # Parsing du contenu avec BeautifulSoup
        soup = BeautifulSoup(response.text, 'html.parser')
        page_text = soup.get_text()

        with col1:
            # Ex√©cution de la fonctionnalit√© standard s√©lectionn√©e
            if option == "Afficher le titre":
                st.subheader("üìå Titre de la page")
                st.write(soup.title.string if soup.title else "Titre non trouv√©")

            elif option == "Afficher tout le texte":
                st.subheader("üìÉ Contenu de la page")
                st.text_area("Texte extrait", page_text, height=300)

            elif option == "Afficher toutes les balises H1":
                headers = [h1.get_text() for h1 in soup.find_all('h1')]
                st.subheader("üìë Balises H1")
                st.write(headers)

            elif option == "Afficher tous les paragraphes":
                paragraphs = [p.get_text() for p in soup.find_all('p')]
                st.subheader("üìÑ Paragraphes")
                st.write(paragraphs)

            elif option == "Afficher tous les liens":
                links = [a['href'] for a in soup.find_all('a', href=True)]
                st.subheader("üîó Liens")
                st.write(links)

            elif option == "Afficher toutes les images":
                images = [img['src'] for img in soup.find_all('img', src=True)]
                st.subheader("üñºÔ∏è Images")
                st.write(images)

            elif option == "Afficher le nombre total de mots":
                word_count = len(page_text.split())
                st.subheader("üî¢ Nombre total de mots")
                st.write(f"Nombre total de mots : {word_count}")

            elif option == "Afficher les m√©tadonn√©es":
                meta_tags = {meta.get('name', 'N/A'): meta.get('content', 'N/A') for meta in soup.find_all('meta')}
                st.subheader("üìú M√©tadonn√©es")
                st.write(meta_tags)

        with col1:
            # Ex√©cution de la fonctionnalit√© IA s√©lectionn√©e
            if option_ai != "Aucune":
                st.subheader(f"ü§ñ Analyse IA : {option_ai}")
                openai.api_key = "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"  # Ma cl√© API OpenAI

                if option_ai == "R√©sum√© automatique":
                    prompt = f"R√©sum√© du texte suivant : {page_text[:2000]}"
                    response = openai.Completion.create(engine="gpt-3.5-turbo", prompt=prompt, max_tokens=100)
                    st.write(response["choices"][0]["text"].strip())

                elif option_ai == "Analyse de sentiment":
                    prompt = f"Analyse du sentiment du texte suivant : {page_text[:2000]}"
                    response = openai.Completion.create(engine="gpt-3.5-turbo", prompt=prompt, max_tokens=50)
                    st.write(response["choices"][0]["text"].strip())

                elif option_ai == "Classification du contenu":
                    prompt = f"Classifie le texte suivant dans une des cat√©gories suivantes : actualit√©s, blog, produit, recherche, autre. Texte : {page_text[:2000]}"
                    response = openai.Completion.create(engine="gpt-3.5-turbo", prompt=prompt, max_tokens=50)
                    st.write(response["choices"][0]["text"].strip())

                elif option_ai == "D√©tection des entit√©s nomm√©es":
                    prompt = f"Identifie les entit√©s nomm√©es dans ce texte : {page_text[:2000]}"
                    response = openai.Completion.create(engine="gpt-3.5-turbo", prompt=prompt, max_tokens=100)
                    st.write(response["choices"][0]["text"].strip())

                elif option_ai == "G√©n√©ration de mots-cl√©s":
                    prompt = f"G√©n√®re des mots-cl√©s pertinents pour le texte suivant : {page_text[:2000]}"
                    response = openai.Completion.create(engine="gpt-3.5-turbo", prompt=prompt, max_tokens=50)
                    st.write(response["choices"][0]["text"].strip())

    except requests.exceptions.RequestException as e:
        st.error(f"‚ùå Erreur lors de la r√©cup√©ration de la page : {e}")
    except Exception as e:
        st.error(f"‚ö†Ô∏è Une erreur est survenue : {e}")
